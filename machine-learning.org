#+TITLE: 机器学习网上参考材料

* 算法与数据结构

** 动态规划
+ 动态规划经典题目汇总 https://blog.csdn.net/dengwei4321/article/details/14137295
+ 面试中的动态规划 https://blog.csdn.net/qq_15288217/article/details/80693352
+ 面试经典动态规划问题 https://blog.csdn.net/u013007900/article/details/56298701
  
** 图搜索
+ 图/树——宽度优先搜索（BFS）https://blog.csdn.net/Echo1214_Xie/article/details/81672803

* 大数据技术 

** Flink技术关键
+ 第一次有人把Apache Flink说的这么明白！ https://www.jianshu.com/p/c5949402134c
+ Flink案例代码，面试题 https://blog.csdn.net/qq_31866793/article/details/90755173 
  
** 推荐类算法

*** 协同过滤
+ 基于物品的协同过滤算法(ItemCF) https://www.cnblogs.com/dtstack/p/10271551.html 
+ 推荐系统之基于用户的协同过滤算法（UserCF） https://blog.csdn.net/sinat_35866463/article/details/79428898
+ 皮尔森相关性的相似度 https://blog.csdn.net/ifnoelse/article/details/7765984

* 机器学习基础 

** 综合机器学习
+ 算法工程师养成记（附精选面试题）http://www.ijiandao.com/2b/baijia/157038.html
  
** Adaboost 
+ 理解AdaBoost算法 https://www.itcodemonkey.com/article/8588.html
  
** 神经网络

*** 神经网络的loss function与bp算法求导
+ 详解机器学习中的熵、条件熵、相对熵和交叉熵 https://www.cnblogs.com/kyrieng/p/8694705.html
+ softmax的log似然代价函数（公式求导）https://blog.csdn.net/u014313009/article/details/51045303
+ 卷积神经网络系列之softmax loss对输入的求导推导 https://blog.csdn.net/weixin_36411839/article/details/81835571
  
*** 神经网络梯度下降的方法

*** Batch Normalization
+ 深入理解Batch Normalization批标准化 https://www.cnblogs.com/guoyaohua/p/8724433.html
  
** SVM资料
+ SVM支持向量机-拉格朗日乘子与对偶问题（1）https://blog.csdn.net/bit_666/article/details/79865225
  
** 统计资料
+ 统计学基础--假设检验 https://blog.csdn.net/andy_shenzl/article/details/81453509
+ 统计学入门（7/7）——假设检验 https://blog.csdn.net/Yi_jia_yi/article/details/81139679

* 计算机视觉

** 卷积神经网络
+ 一文概览Inception家族的奋斗史 http://baijiahao.baidu.com/s?id=1601882944953788623&wfr=spider&for=pc
+ 卷积神经网络的感受野 https://zhuanlan.zhihu.com/p/44106492
+ 细粒度分类：双线性CNN https://zhuanlan.zhihu.com/p/62532887
+ 双线性池化（Bilinear Pooling）详解、改进及应用 https://zhuanlan.zhihu.com/p/62532887

** 视觉Attention模型
+ [计算机视觉]深入理解Attention机制 https://blog.csdn.net/yideqianfenzhiyi/article/details/79422857
  
** 目标检测与目标跟踪
+ 一文读懂Faster RCNN https://zhuanlan.zhihu.com/p/31426458
+ 目标检测中的Anchor https://zhuanlan.zhihu.com/p/55824651
+ 目标跟踪简介 https://www.cnblogs.com/jjwu/p/8512730.html
+ CVPR2018 目标检测（object detection）算法总览 https://blog.csdn.net/niuxinzan/article/details/82107125
+ 非极大值抑制（合并抛弃重合选区间） https://www.cnblogs.com/makefile/p/nms.html
+ Anchor Boxes——目标检测质量的关键 https://baijiahao.baidu.com/s?id=1620728785393443256&wfr=spider&for=pc
+ 如何应用MTCNN和FaceNet模型实现人脸检测及识别 https://cloud.tencent.com/developer/news/213743
  
* 自然语言处理

** Language Model解析
+ 漫谈 Language Model (1): 原理篇 http://blog.pluskid.org/?p=352 
+ 深入理解语言模型 Language Model https://zhuanlan.zhihu.com/p/52061158
+ Bag-of-words模型入门 https://zhuanlan.zhihu.com/p/29933242 
+ 理解 Word2Vec 之 Skip-Gram 模型 https://zhuanlan.zhihu.com/p/27234078

** LDA主题模型
+ 自然语言处理基础与实战（8）- 主题模型LDA理解与应用 https://www.jianshu.com/p/74ec7d5f6821

** NLP Attention模型
+ 模型汇总24 - 深度学习中Attention Mechanism详细介绍：原理、分类及应用 https://zhuanlan.zhihu.com/p/31547842
+ 深度解析注意力模型(attention model) --- image_caption的应用 https://segmentfault.com/a/1190000011744246
+ 深度学习中的注意力模型（2017版）https://zhuanlan.zhihu.com/p/37601161
+ 干货｜如何在语言翻译中理解Attention Mechanism？ http://www.sohu.com/a/156018349_642762
+ 计算机视觉与NLP结合解释Attention Model https://zhuanlan.zhihu.com/p/56501461
+ 深入浅出，详细理解Attention Model的基本原理！ https://www.jianshu.com/p/ff968920ec73 
  
** 基于Attention的Transformer Model
+ Transformer结构及其应用详解--GPT、BERT、MT-DNN、GPT-2 https://zhuanlan.zhihu.com/p/69290203
+ 彻底搞懂BERT https://www.cnblogs.com/rucwxb/p/10277217.html
+ 5 分钟入门 Google 最强NLP模型：BERT https://www.jianshu.com/p/d110d0c13063
  
* 学习流程

** 文本类题
+ 一面
    1. 项目
    2. 关键字怎么提取的，TF-IDF有改进么，怎么改进的
    3. 命名实体怎么得到的，原理了解
    4. LDA的原理是什么，使用了哪个框架
    5. 狄利克雷分布能具体说说么
    6. 深度学习了解么
    7. RNN LSTM了解么
    8. 有什么比较熟悉的算法
    9. xgboost的原理
    10. 有10个排好序的数据库，那么我要找整个的中位数，怎么找
    11. 一个路口，一个小时通过一个车的概率是0.9，那么20分钟内通过车的概率是多少
    12. 我有一个32位的id是唯一的，那么我想压缩一下，让他还唯一，怎么压缩

+ 二面
    1. 项目
    2. SVM原始问题为什么要转化为对偶问题，为什么对偶问题就好求解，原始问题不能求解么
    3. K-means 中我想聚成100类 结果发现只能聚成98类，为什么
    4. 进程中的内存分段是怎样的
    5. 每个线程有哪些东西是自己独享的
    6. 一枚不均匀的硬币，我抛了100次，有70次朝上，那么第101次朝上的概率是多少, 这个概率怎么样，公示是如何推导出来的
    7. 给你个字符串，字符串是个数字，怎么转换为int型，不用库函数的话
    8. 4个海盗，100个金币，每个人轮流提方案，如果你的方案有半数以上通过，那么久可以，否则就会被杀掉，如果你是第一个人，那么你怎么提方案比较好
    9. 你的优点是什么
       
** leetcode 问题题目
1. 编程重点试一下
   + 95: Unique Binary Search Trees II
   + 96: Unique Binary Search Trees 
       
** 机器学习基础

*** SIFT特征与HOG特征的表达式与特性

*** 最小二乘推导

*** 逻辑回归推导

[./algo-pic/logistic_regression.png]

*** 二层神经网络bp算法推导

[./algo-pic/bp.png]

*** 循环神经网络bp公式推导

*** BN层公式推导

*** LSTM公式推导

*** Softmax bp算法推导

[./algo-pic/softmax.png]

*** SVM算法推导

*** AdaBoost算法推导

[./algo-pic/adaboost.png]

*** GBDT算法推导与特点

*** 谱聚类的推导

*** PCA与LDA的推导

** 计算机视觉

** 自然语言处理
+ NLP面试(写的比较全面) https://blog.csdn.net/zongza/article/details/82952553
+ NLP面试 https://blog.csdn.net/qq_24831889/article/details/85876981
+ NLP面试 https://blog.csdn.net/zdz0200/article/details/82628732
+ NLP面试 https://blog.csdn.net/qq_28935065/article/details/79075048

** 大数据方向:

*** Flink方向技巧:
+ waltermark的定义
+ flatMap与map的区别是什么
+ kafka如何保证数据的有序，如果有数据乱序与延迟怎么办
+ 如何保证kafka高性能的消费

*** Spark方向技巧:
+ 宽依赖，窄依赖
+ shuffle的原理
+ hdfs的原理

*** 数据库方向:
+ 为什么业务里要使用es，es的优势在哪里：es查询比较灵活，并且可以有聚合操作
